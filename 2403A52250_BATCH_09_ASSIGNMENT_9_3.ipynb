{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNl3RNjvSuzPccoQCjJfeNN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sathwika2202/NLP/blob/main/2403A52250_BATCH_09_ASSIGNMENT_9_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-3B8XulEhA7",
        "outputId": "d9242649-f600-4829-8acc-d12479a738ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gensim is used to load and work with pre-trained word embedding models\n",
        "# It provides Word2Vec, GloVe, FastText implementations\n",
        "import gensim\n",
        "\n",
        "# KeyedVectors is specifically used to load pre-trained word embeddings\n",
        "# without loading the full training model\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# numpy is used for numerical operations on vectors\n",
        "# Word embeddings are stored as numerical arrays\n",
        "import numpy as np\n",
        "\n",
        "# sklearn.metrics.pairwise is used to calculate similarity between vectors\n",
        "# cosine_similarity helps measure semantic similarity between words\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# matplotlib is used to visualize word embeddings in 2D space\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "F0102MLWF4VZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2033bc8",
        "outputId": "4bfd063e-c8f5-43fc-9fbf-67cf96251a80"
      },
      "source": [
        "import gensim.downloader as api\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Load pre-trained Word2Vec model (may take time on first download)\n",
        "model = api.load(\"word2vec-google-news-300\")\n",
        "\n",
        "# Print vocabulary size\n",
        "print(\"Vocabulary Size:\", len(model.key_to_index))\n",
        "\n",
        "# Display vector for a sample word\n",
        "word = \"king\"\n",
        "vector = model[word]\n",
        "\n",
        "print(\"\\nWord:\", word)\n",
        "print(\"Vector length:\", len(vector))\n",
        "print(\"First 10 values of the vector:\\n\", vector[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
            "Vocabulary Size: 3000000\n",
            "\n",
            "Word: king\n",
            "Vector length: 300\n",
            "First 10 values of the vector:\n",
            " [ 0.12597656  0.02978516  0.00860596  0.13964844 -0.02563477 -0.03613281\n",
            "  0.11181641 -0.19824219  0.05126953  0.36328125]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4639c47",
        "outputId": "942daa8b-3a1e-47b6-d29a-2879d726d07a"
      },
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Load GloVe embeddings (100-dimensional)\n",
        "model = api.load(\"glove-wiki-gigaword-100\")\n",
        "\n",
        "# Print vocabulary size\n",
        "print(\"Vocabulary Size:\", len(model.key_to_index))\n",
        "\n",
        "# Display vector for a sample word\n",
        "word = \"king\"\n",
        "vector = model[word]\n",
        "\n",
        "print(\"\\nWord:\", word)\n",
        "print(\"Vector length:\", len(vector))\n",
        "print(\"First 10 values of the vector:\\n\", vector[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n",
            "Vocabulary Size: 400000\n",
            "\n",
            "Word: king\n",
            "Vector length: 100\n",
            "First 10 values of the vector:\n",
            " [-0.32307 -0.87616  0.21977  0.25268  0.22976  0.7388  -0.37954 -0.35307\n",
            " -0.84369 -1.1113 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Load pre-trained GloVe model (100D)\n",
        "model = api.load(\"glove-wiki-gigaword-100\")\n",
        "\n",
        "# Define word pairs\n",
        "word_pairs = [\n",
        "    (\"doctor\", \"nurse\"),\n",
        "    (\"cat\", \"dog\"),\n",
        "    (\"car\", \"bus\"),\n",
        "    (\"king\", \"queen\"),\n",
        "    (\"man\", \"woman\"),\n",
        "    (\"teacher\", \"student\"),\n",
        "    (\"apple\", \"banana\"),\n",
        "    (\"computer\", \"keyboard\"),\n",
        "    (\"sun\", \"moon\"),\n",
        "    (\"river\", \"water\")\n",
        "]\n",
        "\n",
        "print(\"Word Similarity Scores:\\n\")\n",
        "\n",
        "for w1, w2 in word_pairs:\n",
        "    similarity = model.similarity(w1, w2)\n",
        "    print(f\"{w1} - {w2} : {similarity:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YThak0sXIri9",
        "outputId": "1271742c-c4c6-4ee4-9e13-c9122c0836a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Similarity Scores:\n",
            "\n",
            "doctor - nurse : 0.7522\n",
            "cat - dog : 0.8798\n",
            "car - bus : 0.7373\n",
            "king - queen : 0.7508\n",
            "man - woman : 0.8323\n",
            "teacher - student : 0.8083\n",
            "apple - banana : 0.5054\n",
            "computer - keyboard : 0.5418\n",
            "sun - moon : 0.6138\n",
            "river - water : 0.6306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import gensim.downloader as api\n",
        "\n",
        "# Load pre-trained GloVe embeddings (100D)\n",
        "model = api.load(\"glove-wiki-gigaword-100\")\n",
        "\n",
        "# Choose at least 5 words\n",
        "chosen_words = [\"king\", \"university\", \"doctor\", \"car\", \"music\"]\n",
        "\n",
        "for word in chosen_words:\n",
        "    print(f\"\\nTop similar words for '{word}':\\n\")\n",
        "\n",
        "    similar_words = model.most_similar(word, topn=5)\n",
        "\n",
        "    for similar_word, score in similar_words:\n",
        "        print(f\"{similar_word} : {score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IuiNwwLJM57",
        "outputId": "ed9168bb-0ca0-4f8d-a5cc-34f8f823e126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top similar words for 'king':\n",
            "\n",
            "prince : 0.7682\n",
            "queen : 0.7508\n",
            "son : 0.7021\n",
            "brother : 0.6986\n",
            "monarch : 0.6978\n",
            "\n",
            "Top similar words for 'university':\n",
            "\n",
            "college : 0.8294\n",
            "harvard : 0.8156\n",
            "yale : 0.8114\n",
            "professor : 0.8104\n",
            "graduate : 0.7993\n",
            "\n",
            "Top similar words for 'doctor':\n",
            "\n",
            "physician : 0.7673\n",
            "nurse : 0.7522\n",
            "dr. : 0.7175\n",
            "doctors : 0.7081\n",
            "patient : 0.7074\n",
            "\n",
            "Top similar words for 'car':\n",
            "\n",
            "vehicle : 0.8631\n",
            "truck : 0.8598\n",
            "cars : 0.8372\n",
            "driver : 0.8186\n",
            "driving : 0.7813\n",
            "\n",
            "Top similar words for 'music':\n",
            "\n",
            "musical : 0.8128\n",
            "songs : 0.7978\n",
            "dance : 0.7897\n",
            "pop : 0.7863\n",
            "recording : 0.7651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Load pre-trained Word2Vec (better for analogies)\n",
        "model = api.load(\"word2vec-google-news-300\")\n",
        "\n",
        "# Analogy 1\n",
        "result1 = model.most_similar(\n",
        "    positive=[\"king\", \"woman\"],\n",
        "    negative=[\"man\"],\n",
        "    topn=5\n",
        ")\n",
        "\n",
        "# Analogy 2\n",
        "result2 = model.most_similar(\n",
        "    positive=[\"paris\", \"india\"],\n",
        "    negative=[\"france\"],\n",
        "    topn=5\n",
        ")\n",
        "\n",
        "# Analogy 3\n",
        "result3 = model.most_similar(\n",
        "    positive=[\"teacher\", \"hospital\"],\n",
        "    negative=[\"school\"],\n",
        "    topn=5\n",
        ")\n",
        "\n",
        "print(\"\\nking - man + woman = ?\")\n",
        "print(result1)\n",
        "\n",
        "print(\"\\nparis - france + india = ?\")\n",
        "print(result2)\n",
        "\n",
        "print(\"\\nteacher - school + hospital = ?\")\n",
        "print(result3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BZhqOHSJ4nw",
        "outputId": "ddb5c2cb-f087-4a28-c7ec-492dddda9ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "king - man + woman = ?\n",
            "[('queen', 0.7118193507194519), ('monarch', 0.6189674139022827), ('princess', 0.5902431011199951), ('crown_prince', 0.5499460697174072), ('prince', 0.5377321839332581)]\n",
            "\n",
            "paris - france + india = ?\n",
            "[('chennai', 0.5442505478858948), ('delhi', 0.5149926543235779), ('mumbai', 0.5024341344833374), ('hyderabad', 0.49932485818862915), ('gujarat', 0.48732805252075195)]\n",
            "\n",
            "teacher - school + hospital = ?\n",
            "[('Hospital', 0.6331106424331665), ('nurse', 0.6280134320259094), ('hopsital', 0.6217317581176758), ('intensive_care', 0.5683753490447998), ('Hosptial', 0.5647749304771423)]\n"
          ]
        }
      ]
    }
  ]
}